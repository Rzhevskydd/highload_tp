# highload_tp
Project of "highload" course in technopark

# HighloadArchitectureCourseWork

## 1. Тема и целевая аудитория

В качестве темы был выбран сервис облачного хранилища данных. 
Прототипы:
- [Dropbox](https://www.dropbox.com/) 
- [Yandex.Disk](https://disk.yandex.ru/)
- [Google Drive](https://drive.google.com/)

Проектируемый функционал MVP:
* загрузить файл
* удалить файл
* скачать файл
* посмотреть информацию о файле
* поделиться ссылкой на файл

Положим размер аудитории сервиса 10М, расположение аудитории - Россия.

[Сводная табличка по аналогичным сервисам](https://en.wikipedia.org/wiki/Comparison_of_file_hosting_services)

## 2. Расчет нагрузки

Сервис будет предоставлять **2гб** дискового пространства для бесплатного аккаунта, **1000гб** для платного.
Ограничим объем загружаемых и скачиваемых данных для пользователя за день размером в **20гб/день** для бесплатного аккаунта, **200гб/день** для платного.
Также положим, что **99%** пользователей сервиса имеют бесплатный аккаунт, а **1%** будут иметь платную подписку, т.е. платный аккаунт.
Исходя из этого, получем следующие данные:

|account type|storage|percentage|bandwidth limit|total storage size                             |
|------------|-------|----------|-------------|-----------------------------------------------|
|free        |2GB    |99%       |4GB/day     |2GB * 0.99 * 10 * 10^6 =  19.8PB|
|paid        |1000GB  |1%        |200GB/day    |1000GB * 0.01 * 10 * 10^6 = 10PB   |

Из рассчетов получаем, что суммарных объем хранилища должен составлять **29.8PB**.

Из данных [similarweb](https://www.similarweb.com/website/disk.yandex.ru/):

* средняя продолжительность пребывания на сайте такого проекта около 5 минут
* количество посещений на сайт примерно в 5 раз больше, чем количество пользователей, т.е. пользователь в среднем посещает ресурс 5 раз за месяц => вероятность того что в данный момент времени пользователь пользуется сервисом ~0,167, будем использовать её в качествет коэффициента.

Примем ряд некоторых допущений:
* Пользователи в среднем используют примерно **50%** своего доступного места
* Примем средний размер хранимых файлов **5МБ** (преимущественно хранят - фотографии и документы)
* Примем входящий и исходящий траффик одинаковым по объему (в первоначальном приближении)
* Пиковый трафик будет примерно в **3** раза больше, чем средний по рассчету
* Примем коэффициент запаса равный 3 

Исходя из этого, попытаемся рассчитать средний сетевой трафик:
#### Средний трафик 29,8PB * 0,5 * 0,167 * 3 = 7,5 ПБ/год = 1500 Мбит/сек
#### В период пиковой нагрузки ~6000 Мбит/сек


## 3. Логическая схема БД
![image](https://user-images.githubusercontent.com/46247177/118415460-21f46c80-b6b3-11eb-82e6-45a589182e76.png)

Все файлы на клиенте при загрузке разбиваются на чанки фиксированного размера **4МБ**.
Вся метаинформация о хранимых файлах будет располагаться в так называемых "метасерверах" на физических машинах, весь хранимый контет в виде чанков на "блоксерверах", в качестве хранилища - AWS. Чтобы файлы можно было собрать в обратном порядке, у чанка есть поле `order`.

Исходя из того, что практически все основные операции (чтение, обновление, удалени) будут сводиться к селекту всех блоков одного файла воедино, с целью оптимизации индексации блоков вынесем этот модуль в отдельный сервис - Indexer. 

Ориентировочно:
Для хранения данных пользователей будем использовать PostgreSQL, т.к. в ней доступно настраивается шардирование, таблицы User будут шардироваться по id.

Таблицы  Block будут шардироваться по полю id, каждый инстанс внутри шарда будет партиционироваться с целью облегчить вес таблицы и вес индексов по file_id. 
Memcached для отдачи физических путей расположения серверов у недавно использованных файлов. 

